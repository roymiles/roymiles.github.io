<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <!-- begin SEO -->
  <title>Roy Miles</title>
  <meta property="og:locale" content="en-US">
  <meta property="og:site_name" content="Roy Miles">
  <meta property="og:title" content="Publications">
  <link rel="canonical" href="https://roymiles.github.io/publications/">
  <meta property="og:url" content="https://roymiles.github.io/publications/">
  <script type="application/ld+json"> { "@context" : "http://schema.org", "@type" : "Person", "name" : "Roy Miles", "url" : "https://roymiles.github.io", "sameAs" : null } </script> <!-- end SEO -->
  <link href="https://roymiles.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Roy Miles Feed">
  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script> document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js '; </script> <!-- For all browsers -->
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="stylesheet" href="assets/css/new_main.css">
  <style>
    body {
      background-color: #f9fafb;
    }
    .paper-card {
      border: 1px solid rgba(0,0,0,0.06);
    }
    html {
      scroll-behavior: smooth; /* enables smooth scroll */
    }
  </style>
  <meta http-equiv="cleartype" content="on">
  <!-- start custom head snippets -->
  <link rel="apple-touch-icon" sizes="57x57" href="https://roymiles.github.io/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
  <link rel="apple-touch-icon" sizes="60x60" href="https://roymiles.github.io/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
  <link rel="apple-touch-icon" sizes="72x72" href="https://roymiles.github.io/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
  <link rel="apple-touch-icon" sizes="76x76" href="https://roymiles.github.io/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
  <link rel="apple-touch-icon" sizes="114x114" href="https://roymiles.github.io/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
  <link rel="apple-touch-icon" sizes="120x120" href="https://roymiles.github.io/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
  <link rel="apple-touch-icon" sizes="144x144" href="https://roymiles.github.io/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
  <link rel="apple-touch-icon" sizes="152x152" href="https://roymiles.github.io/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
  <link rel="apple-touch-icon" sizes="180x180" href="https://roymiles.github.io/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
  <!--<link rel="icon" type="image/png" href="https://roymiles.github.io/images/favicon-32x32.png" sizes="32x32"><link rel="icon" type="image/png" href="https://roymiles.github.io/images/favicon-16x16.png" sizes="16x16"> -->
  <link rel="icon" type="image/png" href="https://roymiles.github.io/images/favicon2.png" sizes="32x32">
  <link rel="manifest" href="https://roymiles.github.io/images/manifest.json?v=M44lzPylqQ">
  <link rel="mask-icon" href="https://roymiles.github.io/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
  <link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
  <meta name="msapplication-TileColor" content="#000000">
  <meta name="msapplication-TileImage" content="https://roymiles.github.io/images/mstile-144x144.png?v=M44lzPylqQ">
  <meta name="msapplication-config" content="https://roymiles.github.io/images/browserconfig.xml?v=M44lzPylqQ">
  <meta name="theme-color" content="#ffffff">
  <link rel="stylesheet" href="https://roymiles.github.io/assets/css/academicons.css"/>
  <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } }); </script> <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>
  <meta name="google-site-verification" content="VbL8ZFqn-TqRX7AIia-ZlG7zE0nOSyeRgMMAW1SGe9o" />
  <!-- end custom head snippets -->
</head>
<body class="min-h-screen flex flex-col items-center">
  <!-- Mountain banner across top -->
  <div class="relative w-full h-40 overflow-hidden">
    <svg class="absolute inset-0 w-full h-full" viewBox="0 0 1200 800" preserveAspectRatio="xMidYMid slice">
      <defs>
        <filter id="paperNoise">
          <feTurbulence type="fractalNoise" baseFrequency="0.8" numOctaves="2" stitchTiles="stitch" result="noise" />
          <feColorMatrix type="saturate" values="0" />
          <feComponentTransfer>
            <feFuncA type="table" tableValues="0 0.06" />
          </feComponentTransfer>
        </filter>
        <filter id="pencilShading" x="-20%" y="-20%" width="140%" height="140%">
          <feTurbulence type="fractalNoise" baseFrequency="0.9" numOctaves="3" result="turb" />
          <feDiffuseLighting in="turb" lightingColor="#ffffff" surfaceScale="0.5">
            <feDistantLight azimuth="45" elevation="60" />
          </feDiffuseLighting>
          <feColorMatrix type="matrix" values="0.6 0 0 0 0  0 0.6 0 0 0  0 0 0.6 0 0  0 0 0 1 0" />
        </filter>
        <radialGradient id="vignette" cx="50%" cy="20%" r="80%">
          <stop offset="60%" stop-color="rgba(255,255,255,0.92)" />
          <stop offset="100%" stop-color="rgba(240,240,240,0.9)" />
        </radialGradient>
      </defs>
      <g transform="translate(0,120)">
        <path d="M0,500 L160,320 L260,420 L380,260 L540,460 L760,200 L860,300 L980,180 L1200,500 L1200,800 L0,800 Z" fill="url(#vignette)" opacity="0.8" />
        <path d="M0,500 L160,320 L260,420 L380,260 L540,460 L760,200 L860,300 L980,180 L1200,500" fill="none" stroke="#9b9b9b" stroke-width="2.6" />
        <path d="M0,520 L140,340 L260,440 L400,280 L540,480 L760,220 L860,340 L1000,200 L1200,520" fill="none" stroke="#bdbdbd" stroke-width="1.2" />
        <g filter="url(#pencilShading)" opacity="0.35">
          <path d="M20,520 L160,360 L260,460 L400,300 L540,500 L760,260 L860,360 L1000,240 L1180,520 L1180,640 L20,640 Z" fill="#f3f3f3" />
        </g>
        <rect x="0" y="0" width="1200" height="800" fill="#ffffff" filter="url(#paperNoise)" />
      </g>
    </svg>
  </div>

  <!-- Main content -->
  <div class="w-full max-w-4xl">
    <div class="grid grid-cols-1 md:grid-cols-3">
		<div class="flex fixed justify-center pt-8">
			<div itemscope itemtype="http://schema.org/Person">
			   <div class="author__avatar"> <img src="images/profile.png" class="author__avatar" alt="Roy Miles"></div>
			   <br>
			   <div class="author__content">
				  <h3 class="text-lg font-semibold text-gray-800">Roy Miles</h3>
				  <!-- <p class="mt-1 text-sm text-gray-600">I am currently a Research Scientist at Huawei Noah's Ark UK. My research has been primarily on the topic of building efficient computer vision models and deploying them on resource constrained devices, such as mobile phones.</p> -->
			   </div>
			   <br>
			   <div class="author__urls-wrapper">
				  <button class="btn btn--inverse">Follow</button>
				  <ul class="mt-1 text-xs space-y-2 text-gray-600 social-icons">
					 <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> London, UK</li>
					 <li><a href="https://www.researchgate.net/profile/Roy-Miles" class="hover:text-blue-700 transition-colors duration-200"><i class="fab fa-fw fa-researchgate" aria-hidden="true"></i> ResearchGate</a></li>
					 <li><a href="https://twitter.com/miles12roy" class="hover:text-blue-700 transition-colors duration-200"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
					 <li><a href="https://www.linkedin.com/in/roy-miles" class="hover:text-blue-700 transition-colors duration-200"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
					 <li><a href="https://github.com/roymiles" class="hover:text-blue-700 transition-colors duration-200"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
					 <li><a href="https://www.stackoverflow.com/users/1582331/roy" class="hover:text-blue-700 transition-colors duration-200"><i class="fab fa-fw fa-stack-overflow" aria-hidden="true"></i> Stackoverflow</a></li>
					 <li><a href="https://scholar.google.com/citations?user=Fev4G4YAAAAJ" class="hover:text-blue-700 transition-colors duration-200"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
				  </ul>
			   </div>
			</div>
		</div>

      <main class="md:col-span-4 p-6 ml-40">
		<nav class="fixed top-0 left-0 w-full bg-white shadow-md z-50">
			<ul class="flex justify-center space-x-8 p-4">
			  <li><a href="#publications" class="text-gray-700 hover:text-blue-600">Publications</a></li>
			  <li><a href="#cv" class="text-gray-700 hover:text-blue-600">CV</a></li>
			</ul>
		</nav>
        <section>
          <p class="mt-3 text-base text-gray-700 leading-relaxed">I am currently a Research Scientist at Huawei Noah's Ark UK. My research has been primarily on the topic of building efficient computer vision models and deploying them on resource constrained devices, such as mobile phones.</p>
        </section>
		<section class="mt-6">
			<h3 class="text-base font-semibold text-gray-800">News</h3>
			<div class="mt-4 space-y-4 text-base text-gray-700 table-responsive">
			  <table class="tab">
			   <tbody><tr>
				   <th scope="row">May 23, 2024</th>
				   <td>
				       <a href="https://arxiv.org/abs/2405.17991" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">VeLoRA</a> was accepted to NeurIPS 2024. [<a href="https://github.com/roymiles/VeLoRA" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">code</a>]
				   </td>
				</tr>
				<tr>
				   <th scope="row">Mar 1, 2024</th>
				   <td>
					  Started a permanant role as a research scientist at Huawei!
				   </td>
				</tr>
				<tr>
				   <th scope="row">Feb 26, 2024</th>
				   <td>
					  <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Miles_VkD_Improving_Knowledge_Distillation_using_Orthogonal_Projections_CVPR_2024_paper.pdf" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">VkD</a> was accepted to CVPR 2024. [<a href="https://github.com/roymiles/vkd" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">code</a> / <a href="https://roymiles.github.io/assets/pdf/CVPR24___Poster___VkD.pdf" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">poster</a>]
				   </td>
				</tr>
				<tr>
				   <th scope="row">Dec 12, 2023</th>
				   <td>
					  Passed my PhD with minor corrections [<a href="https://spiral.imperial.ac.uk/handle/10044/1/112354" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">thesis</a>, <a href="https://roymiles.github.io/assets/pdf/thesis.pdf" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">pdf</a>]
				   </td>
				</tr>
				<tr>
				   <th scope="row">Dec 9, 2023</th>
				   <td>
					  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28219" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">SRD</a> was accepted to AAAI 2024. [<a href="https://github.com/roymiles/Simple-Recipe-Distillation" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">code</a>, <a href="https://roymiles.github.io/assets/pdf/AAAI24___Poster.pdf" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">poster</a>]
				   </td>
				</tr>
				<tr>
				   <th scope="row">Jul 1, 2023</th>
				   <td>
					  Started my internship at Huawei Noah's Ark Lab in the Computer Vision team.
				   </td>
				</tr>
				<tr>
				   <th scope="row">Feb 27, 2023</th>
				   <td>
					  <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Miles_MobileVOS_Real-Time_Video_Object_Segmentation_Contrastive_Learning_Meets_Knowledge_Distillation_CVPR_2023_paper.pdf" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">MobileVOS</a> was accepted to CVPR 2023. [<a href="https://roymiles.github.io/assets/pdf/CVPR23___Poster.pdf" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">poster</a>]
				   </td>
				</tr>
			  </tbody></table>
			  <style>
				.tab {border:none}
				.tab tr td {border:none}
			  </style>
		   </div>
		</section>
        <section class="mt-6">
          <h3 id="publications" class="text-base font-semibold text-gray-800 scroll-mt-20">Publications</h3>
          <div class="mt-4 space-y-4 text-sm text-gray-700">
			<article class="max-w-3xl mx-auto bg-white border border-gray-200 rounded-2xl overflow-hidden">
			  <div class="grid grid-cols-1 md:grid-cols-3">
				<div class="md:col-span-1 p-4 table w-full">
					<div class="align-middle table-cell">
					<img src="https://roymiles.github.io/images/velora.png" alt="VeLoRA: Memory Efficient Training using Rank-1 Sub-Token Projections"/>
					</div>
				</div>
				<div class="md:col-span-2 p-4 flex flex-col justify-between">
				  <header>
					<h2 class="text-sm font-bold text-gray-900 hover:text-blue-600 transition-colors">
					  <a href="https://openreview.net/forum?id=bFoQXD7Uls", target="_blank">VeLoRA: Memory Efficient Training using Rank-1 Sub-Token Projections</a>
					</h2>
					<p class="mt-2 text-sm text-gray-500">
					  <u>Roy Miles</u>, Pradyumna Reddy, Ismail Elezi and Jiankang Deng<br>
					  <em>In NeurIPS</em> 2024
					</p>
				  </header>

				  <p class="mt-4 text-gray-600 line-clamp-3">
					Identify and characterise the important components needed for effective model convergence using gradient descent. In doing so we find that the intermediate activations used to implement backpropagation can be excessively compressed without incurring any degradation in performance.
				  </p>

				  <footer class="mt-6 flex items-center gap-4 text-sm">
					<a class="github-button"
					   href="https://github.com/roymiles/VeLoRA"
					   data-icon="octicon-star"
					   data-size="large"
					   data-show-count="true"
					   aria-label="Star ntkme/github-buttons on GitHub">Star</a>
					<a href="https://arxiv.org/abs/2405.17991" target="_blank" class="pb-3 pt-2">
					  <img src="https://img.shields.io/badge/arXiv-2501.12345-b31b1b.svg" alt="arXiv link">
					</a>
					<a href="https://www.semanticscholar.org/paper/VeLoRA%3A-Memory-Efficient-Training-using-Rank-1-Miles-Reddy/f1f85dfdf48c55bff969d397cd60dd8df5d85c4d" target="_blank" class="pb-3 pt-2">
					  <img src="https://img.shields.io/badge/-Semantic%20Scholar-1857B6?style=flat&logo=semanticscholar&logoColor=white">
					</a>
				  </footer>
				</div>
			  </div>
			</article>
			<article class="max-w-3xl mx-auto bg-white border border-gray-200 rounded-2xl overflow-hidden">
			  <div class="grid grid-cols-1 md:grid-cols-3">
				<div class="md:col-span-1 p-4 table w-full">
					<div class="align-middle table-cell">
					<img src="https://roymiles.github.io/images/vkd.PNG" alt="VkD: Improving Knowledge Distillation using Orthogonal Projections"/>
					</div>
				</div>
				<div class="md:col-span-2 p-4 flex flex-col justify-between">
				  <header>
					<h2 class="text-sm font-bold text-gray-900 hover:text-blue-600 transition-colors">
					  <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Miles_VkD_Improving_Knowledge_Distillation_using_Orthogonal_Projections_CVPR_2024_paper.html", target="_blank">VkD: Improving Knowledge Distillation using Orthogonal Projections</a>
					</h2>
					<p class="mt-2 text-sm text-gray-500">
					  <u>Roy Miles</u>, Ismail Elezi and Jiankang Deng <br>
					  <em>In CVPR</em> 2024
					</p>
				  </header>

				  <p class="mt-4 text-gray-600 line-clamp-3">
					Proposed a novel constrained feature distillation method. This method is derived from a small set of core principles, which results in two emerging components: an orthogonal projection and a task-specific normalisation.
				  </p>

				  <footer class="mt-6 flex items-center gap-4 text-sm">
					<a class="github-button"
					   href="https://github.com/roymiles/VkD"
					   data-icon="octicon-star"
					   data-size="large"
					   data-show-count="true"
					   aria-label="Star ntkme/github-buttons on GitHub">Star</a>
					<a href="https://arxiv.org/abs/2403.06213" target="_blank" class="pb-3 pt-2">
					  <img src="https://img.shields.io/badge/arXiv-2501.12345-b31b1b.svg" alt="arXiv link">
					</a>
					<a href="https://www.semanticscholar.org/paper/%24V_%7Bk%7DD%24%3A-Improving-Knowledge-Distillation-Using-Miles-Elezi/a1153143b384a5a776b31ff80468138837b27fa0" target="_blank" class="pb-3 pt-2">
					  <img src="https://img.shields.io/badge/-Semantic%20Scholar-1857B6?style=flat&logo=semanticscholar&logoColor=white">
					</a>
				  </footer>
				</div>
			  </div>
			</article>
			<article class="max-w-3xl mx-auto bg-white border border-gray-200 rounded-2xl overflow-hidden">
			  <div class="grid grid-cols-1 md:grid-cols-3">
				<div class="md:col-span-1 p-4 table w-full">
					<div class="align-middle table-cell">
					<img src="https://roymiles.github.io/images/srd.PNG" alt="Understanding the Role of the Projector in Knowledge Distillation"/>
					</div>
				</div>
				<div class="md:col-span-2 p-4 flex flex-col justify-between">
				  <header>
					<h2 class="text-sm font-bold text-gray-900 hover:text-blue-600 transition-colors">
					  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28219", target="_blank">Understanding the Role of the Projector in Knowledge Distillation</a>
					</h2>
					<p class="mt-2 text-sm text-gray-500">
					  <u>Roy Miles</u> and Krystian Mikolajczyk <br>
					  <em>In AAAI</em> 2024
					</p>
				  </header>

				  <p class="mt-4 text-gray-600 line-clamp-3">
					Revisit the efficacy of knowledge distillation as a function matching and metric learning problem. In doing so we verify three important design decisions, namely the normalisation, soft maximum function, and projection layers as key ingredients.
				  </p>
				  <footer class="mt-6 flex items-center gap-4 text-sm">
					<a class="github-button"
					   href="https://github.com/roymiles/Simple-Recipe-Distillation"
					   data-icon="octicon-star"
					   data-size="large"
					   data-show-count="true"
					   aria-label="Star ntkme/github-buttons on GitHub">Star</a>
					<a href="https://arxiv.org/abs/2303.11098" target="_blank" class="pb-3 pt-2">
					  <img src="https://img.shields.io/badge/arXiv-2501.12345-b31b1b.svg" alt="arXiv link">
					</a>
					<a href="https://www.semanticscholar.org/paper/Understanding-the-Role-of-the-Projector-in-Miles-Mikolajczyk/d24a0b0bda424d011b24228ba90163421f7a31f2" target="_blank" class="pb-3 pt-2">
					  <img src="https://img.shields.io/badge/-Semantic%20Scholar-1857B6?style=flat&logo=semanticscholar&logoColor=white">
					</a>
				  </footer>
				</div>
			  </div>
			</article>
			<article class="max-w-3xl mx-auto bg-white border border-gray-200 rounded-2xl overflow-hidden">
			  <div class="grid grid-cols-1 md:grid-cols-3">
				<div class="md:col-span-1 p-4 table w-full">
					<div class="align-middle table-cell">
					<img src="https://roymiles.github.io/images/mobilevos.png" alt="MobileVOS: Real-time Video Object Segmentation"/>
					</div>
				</div>
				<div class="md:col-span-2 p-4 flex flex-col justify-between">
				  <header>
					<h2 class="text-sm font-bold text-gray-900 hover:text-blue-600 transition-colors">
					  <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Miles_MobileVOS_Real-Time_Video_Object_Segmentation_Contrastive_Learning_Meets_Knowledge_Distillation_CVPR_2023_paper.html", target="_blank">MobileVOS: Real-time Video Object Segmentation</a>
					</h2>
					<p class="mt-2 text-sm text-gray-500">
					  <u>Roy Miles</u>, Mehmet Kerim Yucel, Bruno Manganelli and Albert Saa-Garriga <br>
					  <em>In CVPR</em> 2024
					</p>
				  </header>

				  <p class="mt-4 text-gray-600 line-clamp-3">
					Tackling the problem of semi-supervised video object segmentation on resource-constrained devices, such as mobile phones. We formulate this problem as a distillation task, whereby we demonstrate that small space-time-memory networks with finite memory can achieve competitive results with state of the art, but at a fraction of the computational cost.
				  </p>
				  <footer class="mt-6 flex items-center gap-4 text-sm">
					<a href="https://arxiv.org/abs/2303.07815" target="_blank" class="pb-3 pt-2">
					  <img src="https://img.shields.io/badge/arXiv-2501.12345-b31b1b.svg" alt="arXiv link">
					</a>
					<a href="https://www.semanticscholar.org/paper/MobileVOS%3A-Real-Time-Video-Object-Segmentation-Miles-Yucel/6dab08e8bf55591f45f6fa4259abeb9fd38263ce" target="_blank" class="pb-3 pt-2">
					  <img src="https://img.shields.io/badge/-Semantic%20Scholar-1857B6?style=flat&logo=semanticscholar&logoColor=white">
					</a>
				  </footer>
				</div>
			  </div>
			</article>
			<article class="max-w-3xl mx-auto bg-white border border-gray-200 rounded-2xl overflow-hidden">
			  <div class="grid grid-cols-1 md:grid-cols-3">
				<div class="md:col-span-1 p-4 table w-full">
					<div class="align-middle table-cell">
					<img src="https://roymiles.github.io/images/itrd.png" alt="Information Theoretic Representation Distillation"/>
					</div>
				</div>
				<div class="md:col-span-2 p-4 flex flex-col justify-between">
				  <header>
					<h2 class="text-sm font-bold text-gray-900 hover:text-blue-600 transition-colors">
					  <a href="https://bmvc2022.mpi-inf.mpg.de/0385.pdf", target="_blank">Information Theoretic Representation Distillation </a>
					</h2>
					<p class="mt-2 text-sm text-gray-500">
					  <u>Roy Miles*</u>, Adrian Lopez Rodriguez*, Krystian Mikolajczyk <br>
					  <em>In BMVC</em> 2022
					</p>
				  </header>

				  <p class="mt-4 text-gray-600 line-clamp-3">
					 Introduce two distinct complementary losses inspired by a cheap entropy-like estimator. These losses aim to maximise the correlation and mutual information between the student and teacher representations. 
				  </p>
				  <footer class="mt-6 flex items-center gap-4 text-sm">
					<a class="github-button"
					   href="https://github.com/roymiles/ITRD"
					   data-icon="octicon-star"
					   data-size="large"
					   data-show-count="true"
					   aria-label="Star ntkme/github-buttons on GitHub">Star</a>
					<a href="https://arxiv.org/abs/2112.00459" target="_blank" class="pb-3 pt-2">
					  <img src="https://img.shields.io/badge/arXiv-2501.12345-b31b1b.svg" alt="arXiv link">
					</a>
					<a href="https://www.semanticscholar.org/paper/Information-Theoretic-Representation-Distillation-Miles-Rodr'iguez/bedb5992c7c2941964e62cd075df63c02b7864d5" target="_blank" class="pb-3 pt-2">
					  <img src="https://img.shields.io/badge/-Semantic%20Scholar-1857B6?style=flat&logo=semanticscholar&logoColor=white">
					</a>
				  </footer>
				</div>
			  </div>
			</article>
			<p>See my <a class="text-blue-500 hover:text-blue-700 transition-colors duration-200" href="https://scholar.google.com/citations?user=Fev4G4YAAAAJ" target="_blank">Google Scholar</a> for a full list.</p>
          </div>
        </section>
        <section class="mt-6">
          <h3 id="cv" class="text-base font-semibold text-gray-800 scroll-mt-20">Research and Industry Experience</h3>
          <div class="mt-4 space-y-4 text-sm text-gray-700">
            <article>
              <div class="flex items-baseline justify-between">
                <h4 class="font-medium">Senior Research Scientist — Huawei Noah's Ark Lab</h4>
                <span class="text-sm text-gray-500">01/2023 — Present</span>
              </div>
			  <div class="ml-5">
				  <ul class="list-disc mt-1 text-sm text-gray-600">
				  <li>Foundational research on knowledge distillation for vision-language models.</li>
				  <li>Involved in the recruitment and interviews stages for several permanent and internship positions.</li>
				  <li>Collaboration and leading several successful research projects.</li>
				  <li>Award for outstanding individual contributor in 2024.</li>
				  <li>Managed several interns with their topics on multi-modality learning.</li>
				  <li>Integrated and landed research on parameter efficient fine-tuning with the product camera teams.</li>
				  </ul>
			  </div>
            </article>
            <article>
              <div class="flex items-baseline justify-between">
                <h4 class="font-medium">Research Scientist Intern - Samsung Research UK</h4>
                <span class="text-sm text-gray-500">06/2022 — 01/2023</span>
              </div>
			  <div class="ml-5">
				  <ul class="list-disc mt-1 text-sm text-gray-600">
				  <li>Semi-supervised video object segmentation for mobile devices</li>
				  <li>Novel unification of representation distillation and contrastive learning.</li>
				  <li>Achieved competitive performance despite running up to ×5 faster, and with ×32 fewer parameters.</li>
				  <li>Integrated research code into the Samsungs mobile product.</li>
				  <li>SRUK 2023 Best Paper Award for MobileVOS presented at CVPR. [<a href="https://research.samsung.com/blog/MobileVOS-Real-Time-Video-Object-Segmentation-Contrastive-Learning-Meets-Knowledge-Distillation" class="text-blue-500 hover:text-blue-700 transition-colors duration-200">blog</a>]</li>
				  </ul>
			  </div>
            </article>
            <article>
              <div class="flex items-baseline justify-between">
                <h4 class="font-medium">Software Engineer Intern - Waymont Consulting</h4>
                <span class="text-sm text-gray-500">06/2017 — 09/2017</span>
              </div>
			  <div class="ml-5">
				  <ul class="list-disc mt-1 text-sm text-gray-600">
				  <li>Developed a responsive web GUI with a C++ backend to automate signal processing tests.</li>
				  <li>Replaced previously manual testing system and increased efficiency by hundredfold.</li>
				  </ul>
			  </div>
            </article>
            <article>
              <div class="flex items-baseline justify-between">
                <h4 class="font-medium">Software Engineer Intern - Toshiba Research Europe</h4>
                <span class="text-sm text-gray-500">06/2016 — 09/2016</span>
              </div>
			  <div class="ml-5">
				  <ul class="list-disc mt-1 text-sm text-gray-600">
				  <li>Designed out-of-tree blocks in C++ using the GNURadio signal processing environment.</li>
				  <li>Characterised and linearised a communication channel between two USRP devices.</li>
				  <li>Utilised the RC-5 Infrared standard for short-range and low-data rate IoT applications.</li>
				  </ul>
			  </div>
            </article>
            <article>
              <div class="flex items-baseline justify-between">
                <h4 class="font-medium">Software Engineer Intern - Toshiba Research Europe</h4>
                <span class="text-sm text-gray-500">06/2015 — 09/2015</span>
              </div>
			  <div class="ml-5">
				  <ul class="list-disc mt-1 text-sm text-gray-600">
				  <li>Developed a GUI to operate a motor-driven positioner in conjunction with a VNA.</li>
				  <li>Measured various antenna patterns within an anechoic chamber.</li>
				  <li>VB.NET code to synchronize two X-Y positioners for analyzing propagation channels.</li>
				  </ul>
			  </div>
            </article>
          </div>
        </section>
        <section class="mt-6">
          <h3 class="text-sm font-semibold text-gray-800">Education</h3>
          <div class="mt-3 text-sm text-gray-700">
            <div class="flex items-baseline justify-between">
              <div>PhD, Computer Vision and Machine Learning — Imperial College London</div>
              <div class="text-sm text-gray-500">10/2018 — 12/2023</div>
            </div>
          </div>
          <div class="mt-3 text-sm text-gray-700">
            <div class="flex items-baseline justify-between">
              <div>MEng, Electrical and Electronic Engineering — University of Bristol</div>
              <div class="text-sm text-gray-500">09/2014 — 07/2018</div>
            </div>
          </div>
        </section>
		<section class="mt-6">
			<h3 class="text-base font-semibold text-gray-800">Patents</h3>
			<div class="ml-5">
			  <ul class="list-disc mt-1 text-sm text-gray-600">
			  <li>Real-Time Video Object Segmentation. Patent <a class="text-blue-500 hover:text-blue-700 transition-colors duration-200" href="https://www.ipo.gov.uk/p-ipsum/Case/PublicationNumber/GB2626221">#GB2626221</a>. Samsung Research UK.</li>
			  <li>Region-aware Foundational Vision Model. Huawei Noah's Ark Lab UK. Patent Pending.</li>
			  <li>Visual Grounding for Vision-Language Models. Huawei Noah's Ark Lab UK. Patent Pending.</li>
			  <li>Training-Free Image Retouching. Huawei Noah's Ark Lab UK. Patent Pending.</li>
			  </ul>
			</div>
		</section>
		<section class="mt-6">
			<h3 class="text-base font-semibold text-gray-800">Reviewing Experience</h3>
			<p class="mt-3 text-sm text-gray-700">• ICCV 2025 • AAAI 2025 • PAMI 2023, 2024 • ECCV 2022 2024 • CVPR 2023, 2024, 2025 • NeurIPS 2023, 2024 • BMVC 2021, 2022 • Neurocomputing 2024 • ICSOC 2024 • Neural Networks 2025</p>
			<p class="mt-3 text-sm text-gray-700"><a class="text-blue-500 hover:text-blue-700 transition-colors duration-200" href="https://neurips.cc/Conferences/2024/ProgramCommittee" target="_blank">NeurIPS 2024 outstanding reviewer</a></p>
		</section>
		<section class="mt-6 flex flex-wrap gap-3">
          <a href="#" class="text-sm border border-gray-200 rounded-full px-3 py-1 shadow-sm">Download PDF</a>
          <a href="https://www.linkedin.com/in/roy-miles/" class="text-sm border border-gray-200 rounded-full px-3 py-1 shadow-sm">Contact</a>
        </section>
        <!--<div class="mt-4 text-xs text-gray-500">Designed with a pencil aesthetic • Simple, print-friendly layout</div>-->
      </main>
    </div>
  </div>
<script async defer src="https://buttons.github.io/buttons.js"></script>
</body>
</html>
